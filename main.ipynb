{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je m'appelle Rick et je suis intéressé par l'apprentissage en machine.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = translator(\"My name is Rick, and I am interested in Machine Learning\")\n",
    "fr[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pysrt.srtitem.SubRipItem object at 0x7fcd27f04ed0>, <pysrt.srtitem.SubRipItem object at 0x7fcd20842450>, <pysrt.srtitem.SubRipItem object at 0x7fce0c62b550>, <pysrt.srtitem.SubRipItem object at 0x7fcd27aaa890>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d4873d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd27aa9650>, <pysrt.srtitem.SubRipItem object at 0x7fcd27aa9350>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d673190>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d487910>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d487610>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d487c10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d487d10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d4e4150>, <pysrt.srtitem.SubRipItem object at 0x7fcd27c5c450>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d75d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d487c90>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d7210>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d6c90>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d3d9710>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d7ed0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d6d10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d71d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d4e43d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d6110>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d53d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d5e50>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d6a10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d7d10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d038a10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d5d50>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d6150>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d0392d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d77d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03aed0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03a790>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03b5d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d038990>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d0398d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03a3d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d5690>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03aa90>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d1d66d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d039f10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03b1d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03b2d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03bc50>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03a0d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03ba90>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03ad10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03ab10>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03a450>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d0388d0>, <pysrt.srtitem.SubRipItem object at 0x7fcd7d03a610>]\n"
     ]
    }
   ],
   "source": [
    "# Take video captions in SRT format and translate them\n",
    "import pysrt\n",
    "\n",
    "subs = pysrt.open(\"captions_english.srt\")\n",
    "print(subs)\n",
    "for i in subs:\n",
    "    fr_text = translator(i.text)[0]['translation_text']\n",
    "    i.text = fr_text\n",
    "\n",
    "subs.save(\"captions_french.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
